{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:29:32.842291300Z",
     "start_time": "2023-11-27T14:29:32.773292300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from keras.src.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, *layers):\n",
    "        self.logistic = lambda z: 1 / (1 + np.exp(-z))\n",
    "        self.logistic_cdf = lambda c, z: c * self.logistic(z) * (1 - self.logistic(z))\n",
    "        self.softmax = lambda z: np.exp(z) / np.sum(np.exp(z), axis=-1)[..., np.newaxis]\n",
    "        self.softmax_cdf = lambda c, z: c @ (self.softmax(z) * (np.eye(len(z)) - self.softmax(z)[:, np.newaxis]))\n",
    "\n",
    "        self.layers_count = len(layers) - 1\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        for l in range(self.layers_count):\n",
    "            self.w.append(np.empty((layers[l], layers[l + 1]), dtype=np.float64))\n",
    "            self.b.append(np.empty(layers[l + 1], dtype=np.float64))\n",
    "\n",
    "        self.f = []\n",
    "        self.cdf = []\n",
    "        for l in range(self.layers_count - 1):\n",
    "            self.f.append(self.logistic)\n",
    "            self.cdf.append(self.logistic_cdf)\n",
    "        self.f.append(self.softmax)\n",
    "        self.cdf.append(self.softmax_cdf)\n",
    "\n",
    "    def train(self, x, y, gens, lr):\n",
    "        \"\"\"\n",
    "        :type x: 2d np.ndarray\n",
    "        :type y: 2d np.ndarray\n",
    "        :type gens: positive int\n",
    "        :type lr: float between 0 and 1\n",
    "        \"\"\"\n",
    "        z = []\n",
    "        a = []\n",
    "        c = []\n",
    "        cdf = []\n",
    "        for l in range(self.layers_count):\n",
    "            r = np.sqrt(6 / (self.w[l].shape[0] + self.w[l].shape[1]))\n",
    "            self.w[l][:, :] = rng.uniform(-r, r, size=self.w[l].shape)\n",
    "            self.b[l][:] = 0\n",
    "            z.append(np.empty_like(self.b[l]))\n",
    "            a.append(np.empty_like(self.b[l]))\n",
    "            c.append(np.empty_like(self.b[l]))\n",
    "            cdf.append(np.empty_like(self.b[l]))\n",
    "\n",
    "        for g in range(gens):\n",
    "            it = np.arange(len(x))\n",
    "            rng.shuffle(it)\n",
    "            for i in it:\n",
    "                z[0][:] = x[i] @ self.w[0] + self.b[0]\n",
    "                a[0][:] = self.f[0](z[0])\n",
    "                for l in range(1, self.layers_count):\n",
    "                    z[l][:] = a[l - 1] @ self.w[l] + self.b[l]\n",
    "                    a[l][:] = self.f[l](z[l])\n",
    "\n",
    "                c[-1][:] = a[-1] - y[i]\n",
    "                cdf[-1][:] = self.cdf[-1](c[-1], z[-1])\n",
    "                for l in range(self.layers_count - 2, -1, -1):\n",
    "                    c[l][:] = cdf[l + 1] @ self.w[l + 1].T\n",
    "                    cdf[l][:] = self.cdf[l](c[l], z[l])\n",
    "\n",
    "                for l in range(self.layers_count):\n",
    "                    cdf[l] *= lr\n",
    "                self.w[0] -= cdf[0] * x[i][:, np.newaxis]\n",
    "                self.b[0] -= cdf[0]\n",
    "                for l in range(1, self.layers_count):\n",
    "                    self.w[l] -= cdf[l] * a[l - 1][:, np.newaxis]\n",
    "                    self.b[l] -= cdf[l]\n",
    "            print('Generation', g, 'Accuracy', accuracy(y, self.predict(x)))\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x: np.ndarray\n",
    "        :return: np.ndarray\n",
    "        \"\"\"\n",
    "        a = self.f[0](x @ self.w[0] + self.b[0])\n",
    "        for l in range(1, self.layers_count):\n",
    "            a = self.f[l](a @ self.w[l] + self.b[l])\n",
    "        return a\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return accuracy_score(np.argmax(y_true, axis=-1).reshape(-1), np.argmax(y_pred, axis=-1).reshape(-1))\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    return f1_score(np.argmax(y_true, axis=-1).reshape(-1), np.argmax(y_pred, axis=-1).reshape(-1), average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:29:34.529913300Z",
     "start_time": "2023-11-27T14:29:34.485912900Z"
    }
   },
   "id": "67b643e272a6b799"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Accuracy 0.638095238095238\n",
      "Generation 1 Accuracy 0.6952380952380952\n",
      "Generation 2 Accuracy 0.6952380952380952\n",
      "Generation 3 Accuracy 0.6952380952380952\n",
      "Generation 4 Accuracy 0.6952380952380952\n",
      "Generation 5 Accuracy 0.6952380952380952\n",
      "Generation 6 Accuracy 0.9333333333333333\n",
      "Generation 7 Accuracy 0.8857142857142857\n",
      "Generation 8 Accuracy 0.8476190476190476\n",
      "Generation 9 Accuracy 0.7047619047619048\n",
      "Generation 10 Accuracy 0.7619047619047619\n",
      "Generation 11 Accuracy 0.8666666666666667\n",
      "Generation 12 Accuracy 0.7142857142857143\n",
      "Generation 13 Accuracy 0.9238095238095239\n",
      "Generation 14 Accuracy 0.819047619047619\n",
      "Generation 15 Accuracy 0.9428571428571428\n",
      "Generation 16 Accuracy 0.8761904761904762\n",
      "Generation 17 Accuracy 0.9428571428571428\n",
      "Generation 18 Accuracy 0.9142857142857143\n",
      "Generation 19 Accuracy 0.8380952380952381\n",
      "Generation 20 Accuracy 0.9809523809523809\n",
      "Generation 21 Accuracy 0.8666666666666667\n",
      "Generation 22 Accuracy 0.8857142857142857\n",
      "Generation 23 Accuracy 0.9809523809523809\n",
      "Generation 24 Accuracy 0.9142857142857143\n",
      "Accuracy 0.9777777777777777\n",
      "F1 0.9776336336336338\n"
     ]
    }
   ],
   "source": [
    "def iris_test():\n",
    "    iris = load_iris()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(iris.data, to_categorical(iris.target), train_size=0.7)\n",
    "    p = Perceptron(4, 5, 3)\n",
    "    p.train(x_train, y_train, 25, 0.1)\n",
    "    print('Accuracy', accuracy(y_test, p.predict(x_test)))\n",
    "    print('F1', f1(y_test, p.predict(x_test)))\n",
    "\n",
    "iris_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:10.184322900Z",
     "start_time": "2023-11-27T14:31:09.594920800Z"
    }
   },
   "id": "18c2a0d001c28237"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Accuracy 0.9251\n",
      "Generation 1 Accuracy 0.9467\n",
      "Generation 2 Accuracy 0.9605\n",
      "Generation 3 Accuracy 0.9718\n",
      "Generation 4 Accuracy 0.9761\n",
      "Generation 5 Accuracy 0.9799\n",
      "Generation 6 Accuracy 0.9831\n",
      "Generation 7 Accuracy 0.9833\n",
      "Generation 8 Accuracy 0.9881\n",
      "Generation 9 Accuracy 0.9897\n",
      "Generation 10 Accuracy 0.9918\n",
      "Generation 11 Accuracy 0.9927\n",
      "Generation 12 Accuracy 0.9925\n",
      "Generation 13 Accuracy 0.9936\n",
      "Generation 14 Accuracy 0.994\n",
      "Generation 15 Accuracy 0.9947\n",
      "Generation 16 Accuracy 0.9947\n",
      "Generation 17 Accuracy 0.995\n",
      "Generation 18 Accuracy 0.9951\n",
      "Generation 19 Accuracy 0.9952\n",
      "Accuracy 0.9529\n",
      "F1 0.9528699203319375\n"
     ]
    }
   ],
   "source": [
    "def mnist_test():\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    n = 10000\n",
    "    train_images = train_images[:n]\n",
    "    train_labels = train_labels[:n]\n",
    "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "    x_train = np.reshape(train_images, (len(train_images), -1))\n",
    "    x_test = np.reshape(test_images, (len(test_images), -1))\n",
    "    y_train = to_categorical(train_labels)\n",
    "    y_test = to_categorical(test_labels)\n",
    "    p = Perceptron(x_train.shape[1], 64, y_train.shape[1])\n",
    "    p.train(x_train, y_train, 20, 0.2)\n",
    "    print('Accuracy', accuracy(y_test, p.predict(x_test)))\n",
    "    print('F1', f1(y_test, p.predict(x_test)))\n",
    "\n",
    "mnist_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:32:17.500359800Z",
     "start_time": "2023-11-20T11:29:42.548758200Z"
    }
   },
   "id": "218a5cfe89eb34ea"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Accuracy 0.9973842129558393\n",
      "Generation 1 Accuracy 1.0\n",
      "Generation 2 Accuracy 1.0\n",
      "Generation 3 Accuracy 1.0\n",
      "Generation 4 Accuracy 1.0\n",
      "Accuracy 1.0\n",
      "F1 1.0\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/uciml/mushroom-classification\n",
    "\n",
    "def mushroom_test():\n",
    "    df = pd.read_csv('mushrooms.csv')\n",
    "    df = pd.get_dummies(df)\n",
    "    df_train, df_test = train_test_split(df, train_size=0.8)\n",
    "    x_train = df_train.drop(columns=['class_e', 'class_p']).to_numpy().astype(np.uint8)\n",
    "    x_test = df_test.drop(columns=['class_e', 'class_p']).to_numpy().astype(np.uint8)\n",
    "    y_train = df_train[['class_e', 'class_p']].to_numpy().astype(np.uint8)\n",
    "    y_test = df_test[['class_e', 'class_p']].to_numpy().astype(np.uint8)\n",
    "    p = Perceptron(x_train.shape[1], 128, y_train.shape[1])\n",
    "    p.train(x_train, y_train, 5, 0.1)\n",
    "    print('Accuracy', accuracy(y_test, p.predict(x_test)))\n",
    "    print('F1', f1(y_test, p.predict(x_test)))\n",
    "\n",
    "mushroom_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:30:41.609500Z",
     "start_time": "2023-11-27T14:30:23.093841700Z"
    }
   },
   "id": "78019e9e1746708f"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 Accuracy 0.9368242103026287\n",
      "Generation 1 Accuracy 0.9109113863923299\n",
      "Generation 2 Accuracy 0.959449493118664\n",
      "Generation 3 Accuracy 0.951986899836248\n",
      "Generation 4 Accuracy 0.9654120676508456\n",
      "Generation 5 Accuracy 0.9616495206190078\n",
      "Generation 6 Accuracy 0.9643370542131776\n",
      "Generation 7 Accuracy 0.9145864323304042\n",
      "Generation 8 Accuracy 0.9645620570257128\n",
      "Generation 9 Accuracy 0.967174589682371\n",
      "Accuracy 0.96805\n",
      "F1 0.9679298908497814\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17\n",
    "\n",
    "def star_test():\n",
    "    df = pd.read_csv('star_classification.csv')\n",
    "    df = df[['u', 'g', 'r', 'i', 'z', 'redshift', 'class']]\n",
    "    df = pd.get_dummies(df, columns=['class'])\n",
    "    df = df[(df[['u', 'g', 'r', 'i', 'z']] >= 0).all(axis=1)]\n",
    "    df_train, df_test = train_test_split(df, train_size=0.8)\n",
    "    x_train = df_train.drop(columns=['class_GALAXY', 'class_QSO', 'class_STAR']).to_numpy()\n",
    "    x_test = df_test.drop(columns=['class_GALAXY', 'class_QSO', 'class_STAR']).to_numpy()\n",
    "    y_train = df_train[['class_GALAXY', 'class_QSO', 'class_STAR']].to_numpy().astype(np.uint8)\n",
    "    y_test = df_test[['class_GALAXY', 'class_QSO', 'class_STAR']].to_numpy().astype(np.uint8)\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    p = Perceptron(x_train.shape[1], 32, 32, y_train.shape[1])\n",
    "    p.train(x_train, y_train, 10, 0.1)\n",
    "    print('Accuracy', accuracy(y_test, p.predict(x_test)))\n",
    "    print('F1', f1(y_test, p.predict(x_test)))\n",
    "\n",
    "star_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:47:36.910894100Z",
     "start_time": "2023-11-20T11:43:36.190606700Z"
    }
   },
   "id": "81b8573f03f356d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1619d3e2978f40ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
